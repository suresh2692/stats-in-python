{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDf = stats.norm(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.29060333e-04   5.44108652e-04   6.87137938e-04   8.64165209e-04\n",
      "   1.08230048e-03   1.34989803e-03   1.67671823e-03   2.07409836e-03\n",
      "   2.55513033e-03   3.13484226e-03   3.83038057e-03   4.66118802e-03\n",
      "   5.64917276e-03   6.81886227e-03   8.19753592e-03   9.81532863e-03\n",
      "   1.17052981e-02   1.39034475e-02   1.64486958e-02   1.93827871e-02\n",
      "   2.27501319e-02   2.65975740e-02   3.09740757e-02   3.59303191e-02\n",
      "   4.15182197e-02   4.77903523e-02   5.47992917e-02   6.25968728e-02\n",
      "   7.12333774e-02   8.07566592e-02   9.12112197e-02   1.02637252e-01\n",
      "   1.15069670e-01   1.28537149e-01   1.43061192e-01   1.58655254e-01\n",
      "   1.75323945e-01   1.93062337e-01   2.11855399e-01   2.31677575e-01\n",
      "   2.52492538e-01   2.74253118e-01   2.96901429e-01   3.20369191e-01\n",
      "   3.44578258e-01   3.69441340e-01   3.94862910e-01   4.20740291e-01\n",
      "   4.46964883e-01   4.73423536e-01   5.00000000e-01   5.26576464e-01\n",
      "   5.53035117e-01   5.79259709e-01   6.05137090e-01   6.30558660e-01\n",
      "   6.55421742e-01   6.79630809e-01   7.03098571e-01   7.25746882e-01\n",
      "   7.47507462e-01   7.68322425e-01   7.88144601e-01   8.06937663e-01\n",
      "   8.24676055e-01   8.41344746e-01   8.56938808e-01   8.71462851e-01\n",
      "   8.84930330e-01   8.97362748e-01   9.08788780e-01   9.19243341e-01\n",
      "   9.28766623e-01   9.37403127e-01   9.45200708e-01   9.52209648e-01\n",
      "   9.58481780e-01   9.64069681e-01   9.69025924e-01   9.73402426e-01\n",
      "   9.77249868e-01   9.80617213e-01   9.83551304e-01   9.86096552e-01\n",
      "   9.88294702e-01   9.90184671e-01   9.91802464e-01   9.93181138e-01\n",
      "   9.94350827e-01   9.95338812e-01   9.96169619e-01   9.96865158e-01\n",
      "   9.97444870e-01   9.97925902e-01   9.98323282e-01   9.98650102e-01\n",
      "   9.98917700e-01   9.99135835e-01   9.99312862e-01   9.99455891e-01\n",
      "   9.99570940e-01]\n"
     ]
    }
   ],
   "source": [
    "X = np.linspace(-5,15,101)\n",
    "y = myDf.cdf(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Distributions\n",
    "Two discrete distributions are frequently encountered: the ___binomial distribution___ and the ___Poisson distribution___.\n",
    "\n",
    "- **Binomial distribution**- It has an inherent upper limit. Ex:- when you throw dice ﬁve times, each side can come up a maximum of *ﬁve times*(limited to five times).\n",
    "\n",
    "- ** Poisson distribution**- It doesn't have an upper limit. Ex:- Number of people you know(there is no limit). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Distribution\n",
    "The simplest case of a _univariate distribution_, and also the _basis of the binomial distribution_, is the Bernoulli distribution which has only *two states*.\n",
    "\n",
    "Ex:- If we ﬂip a coin (and the coin is not rigged) ***once***, the chance that “heads” comes up is P(heads) = 0.5 And since it has to be heads or tails,we must have P(heads) + P(tails) = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "bernoulliDist = stats.bernoulli(p)\n",
    "\n",
    "# since this is categorical, we must use \"pmf\"\n",
    "p_tails = bernoulliDist.pmf(0)  # probability mass function\n",
    "p_heads = bernoulliDist.pmf(1)\n",
    "\n",
    "# for 10 bernoulli trails\n",
    "\n",
    "trials = bernoulliDist.rvs(10) # random variate sample\n",
    "print(trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial distribution\n",
    "It has an inherent upper limit. the binomial distribution is associated with the question “Out of a given (ﬁxed) number of trials,how many will succeed?”.\n",
    "\n",
    "Ex:- If we ﬂip a coin ___multiple times___, and ask “How often did heads come up?” then, we have the binomial distribution. Few other examples are\n",
    "\n",
    "- Out of ten tosses, how many times will this coin land heads?\n",
    "- From the children born in a given hospital on a given day, how many of them will be girls?\n",
    "- How many students in a given classroom will have green eyes?\n",
    "- How many mosquitoes, out of a swarm, will die when sprayed with insecticide?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Poisson distribution\n",
    "\n",
    "The poisson distribution is similar to binomial distribution. The difference is:-\n",
    "- Binomail distribution looks at how many times we register the success over fixed no:of trials.\n",
    "- Poisson distribution looks at how many times an event occurs over a given period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal or Gaussian distribution\n",
    "It is the most important of all the distribution functions. The _standard normal distribution_ is a normal distribution with\n",
    "a mean of zero and a standard deviation of one, and is sometimes referred to as *z-distribution*.\n",
    "\n",
    "**Examples**\n",
    "- If the average man is 175 cm tall with a standard deviation of 6 cm, what is the probability that a man selected at random will be 183 cm tall?\n",
    "- If cans are assumed to have a standard deviation of 4 g, what does the average weight need to be in order to ensure that 99 % of all cans have a weight of at least 250 g?\n",
    "- If the average man is 175 cm tall with a standard deviation of 6 cm, and the average woman is 168 cm tall with a standard deviation of 3 cm, what is the probability that a randomly selected man will be shorter than a randomly selected woman?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.37197479, -0.62802521])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "mu = -2\n",
    "sigma = 0.7\n",
    "myDistribution = stats.norm(mu,sigma)\n",
    "significance_level = 0.05    # probability (percentage is given)\n",
    "\n",
    "# to find the value when percentage is given, use PPF\n",
    "myDistribution.ppf([significance_level/2, 1-significance_level/2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "**mean** of the distributed random samples will also be ___normally distributed___."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students t- distribution\n",
    "When the *population mean* and *variance* are unknown, we use *t-distribution* to approximate *standard error(SE)* of the mean from sample data.\n",
    "\n",
    "**t-ditribution** converges for larger values towards *normal distribution*.\n",
    "\n",
    "    A very frequent application of the t-distribution is in the calculation of conﬁdence intervals for the mean. The width of the 95 %-conﬁdence interval (CI), i.e., the interval that contains the true mean with a chance of 95 %, is the same width about the population mean that contains 95 % of the sample means.\n",
    "    \n",
    "The following example shows how to calculate the t-values for the 95 %-CI, for n = 20. The lower end of the 95 % CI is the value that is larger than 2.5 % of the distribution; and the upper end of the 95 %-CI is the value that is larger than 97.5 % of the distribution. These values can be obtained either with the percentile point function (PPF), or with the inverse survival function (ISF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-distribution = 2.0930240544082634\n",
      "normal-distribution = 1.9599639845400545\n",
      "confidence interval =  (43.743490583289677, 55.256509416710323)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "n = 20\n",
    "df = n-1 #degree of freedom\n",
    "alpha = 0.05 \n",
    "\n",
    "# t-distribution value taking just 20 values\n",
    "t_val = stats.t(df).isf(alpha/2)\n",
    "\n",
    "# normal-distribution value for whole dataset\n",
    "norm_val = stats.norm.isf(alpha/2)\n",
    "\n",
    "print('t-distribution = {0}\\nnormal-distribution = {1}'.format(t_val,norm_val))\n",
    "\n",
    "# 95% confidence interval for mean \n",
    "data = np.arange(0,100)\n",
    "new_alpha = 0.95\n",
    "new_df = len(data)-1\n",
    "ci = stats.t.interval(new_alpha, new_df,loc=np.mean(data), scale=stats.sem(data))\n",
    "print('confidence interval = ',ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can clearly see that **t-distribution ~= normal-distribution**.\n",
    "\n",
    "**Advantage**\n",
    "- The t-distribution is much more roboust against outliers than normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square Distribution\n",
    "The chi-square distribution is related to the normal distribution in a simple way. If a random variable 'x' has *normal distribution*, then X^2 has *chi-square distribution*.\n",
    "\n",
    "The sum of squares of 'n' *independent* and *standard normal random variables* have a **chi-square distribution** with *n degrees of freedom*.\n",
    "\n",
    "**Application Example**\n",
    "\n",
    "    A pill producer is ordered to deliver pills with a standard deviation of \u0002 D 0:05. From the next batch of pills n D 13 random samples have a weight of 3.04, 2.94, 3.01, 3.00, 2.94, 2.91, 3.02, 3.04, 3.09, 2.95, 2.99, 3.10, 3.02 g.\n",
    "    \n",
    "** Question** : Is the standard deviation of produced pills larger than allowed?\n",
    "\n",
    "** Answer** : Since the chi-square distribution describes the distribution of the summed squares of random variates from a standard normal distribution,we have to normalize our data before we calculate the corresponding CDF-value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.192933066543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = np.r_[3.04, 2.94, 3.01, 3.00, 2.94, 2.91, 3.02,\n",
    "3.04, 3.09, 2.95, 2.99, 3.10, 3.02]\n",
    "sigma = 0.05\n",
    "\n",
    "chi2Dist = stats.chi2(len(data)-1) # degree of freedom = n-1\n",
    "statistic = sum(((data-np.mean(data))/sigma)**2)\n",
    "\n",
    "#now we got the value, calculate probability using survival function\n",
    "probability = chi2Dist.sf(statistic)\n",
    "\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "    If the batch of pills is from a distribution with a standard deviation = 0.05, the likelihood of obtaining a chi-square value as large or larger than the one observed is about 19 %, so it is not atypical. In other words, the batch matches the expected standard deviation\n",
    "    \n",
    "\"The chances of obtaining value larger than 0.05 is only **19%**, Hence the produced pills matches the expected standard deviation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Distribution\n",
    "It is used in determining critical values in ANOVAs(\"ANalysis Of VAriance”). If we want to investigate whether two groups have the same variance, we have to calculate the ratio of the sample standard deviations squared.\n",
    "\n",
    "** Application Example**\n",
    "\n",
    "    Take for example the case where we want to compare the precision of two methods to measure eye movements. The two methods can have different accuracy and different precision. As shown in Fig. 6.17,the accuracy gives the deviation between the real and the measured value, while the precision is determined by the variance of the measurements. With the test we want to determine if the precision of the two methods is equivalent, or if one method is more precise than the other.\n",
    "    \n",
    "When you look 20 degree to the right, you get the following results:\n",
    "- Method 1: [20.7, 20.3, 20.3, 20.3, 20.7, 19.9, 19.9, 19.9, 20.3, 20.3, 19.7, 20.3]\n",
    "- Method 2: [ 19.7, 19.4, 20.1, 18.6, 18.8, 20.2, 18.7, 19. ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-tail = 0.018665169931411433, which is not between 2.5 to 97.5\n",
      "\n",
      "Hence,There is a significant difference between the two distributions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "method1 = np.array([20.7, 20.3, 20.3, 20.3, 20.7, 19.9,\n",
    "19.9, 19.9, 20.3, 20.3, 19.7, 20.3])\n",
    "method2 = np.array([ 19.7, 19.4, 20.1, 18.6, 18.8, 20.2,\n",
    "18.7, 19. ])\n",
    "\n",
    "\n",
    "fval = np.var(method1, ddof=1)/np.var(method2, ddof=1)# degree of freedom = 1\n",
    "fd = stats.f(len(method1)-1,len(method2)-1)\n",
    "p_oneTail = fd.cdf(fval) # cdf of f-distribution\n",
    "\n",
    "if (p_oneTail<0.025) or (p_oneTail>0.975):\n",
    "    print('p-tail = {}, which is not between 2.5 to 97.5'.format(p_oneTail))\n",
    "    print('\\nHence,There is a significant difference'\n",
    "' between the two distributions.')\n",
    "else:\n",
    "    print('No significant difference.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "    The F statistic is F D 0:244, and has n \u00021 and m \u00021 degrees of freedom, where n and m are the number of recordings with each method. The code sample below shows that the F statistic is in the tail of the distribution (p_oneTail=0.019), so we reject the hypothesis that the two methods have the same precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other distributions\n",
    "\n",
    "- **Lognormal distribution**: A normal distribution, plotted on an exponential scale. A logarithmic transformation of the data is often used to convert a strongly skewed distribution into a normal one.\n",
    "\n",
    "- **Weibull distribution**: Mainly used for reliability or survival data.\n",
    "- **Exponential distribution**: Exponential curves.\n",
    "- **Uniform distribution**: When everything is equally likely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
